{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnMc_ON7Cy35"
      },
      "source": [
        "# Formative 2: Hate Speech Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ7EMXbZCy4A"
      },
      "outputs": [],
      "source": [
        "# Load relevant packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import csv\n",
        "import operator\n",
        "import random\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, confusion_matrix, accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.options.mode.chained_assignment = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z--z205lCy4D"
      },
      "source": [
        "## 1) Preparing and describing the dataset\n",
        "For this Formative, we are working with a dataset labelled for hate and abuse by Founta et al. (2018)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJXGChZTCy4E"
      },
      "source": [
        "#### 1a) Load the tweets\n",
        "Using pandas, load the .csv dataset for Formative 2 to a dataframe called *df*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDyfRybKCy4E"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./0_data/founta2018_formative2.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBz1nzOsCy4F"
      },
      "source": [
        "Inspect a random sample of 10 tweets in the dataset to get an idea of the kind of content you will be working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPzpy6BACy4G",
        "outputId": "08ab5093-a20e-4716-bae7-97e1e34a33e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beats by Dr. Dre urBeats Wired In-Ear Headphones - White https://t.co/9tREpqfyW4 https://t.co/FCaWyWRbpE</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @Papapishu: Man it would fucking rule if we had a party that was against perpetual warfare.</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It is time to draw close to Him üôèüèª Father, I draw near to you now and always ‚ù§Ô∏è https://t.co/MVRBBX2aqJ</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>if you notice me start to act different or distant.. it's bc i peeped something you did or i notice a difference in how you act &amp; ian fw it.</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Forget unfollowers, I believe in growing. 7 new followers in the last day! Stats via https://t.co/bunPHQNXhj</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RT @Vitiligoprince: Hate Being sexually Frustrated Like I wanna Fuck But ion wanna Just fuck anybody</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Topped the group in TGP Disc Jam Season 2! Onto the Semi-Finals! @HighHorseGames https://t.co/N7LE8lX7Rm</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>That daily baby aspirin for your #heart just might be preventing colon #cancer too. https://t.co/2TLawmHhEe</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I liked a @YouTube video from @mattshea https://t.co/niSeJrLKHq THE BLUE ARMY IS COMING! - Ancient Warfare 2</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RT @LestuhGang_: If your fucking up &amp; your homies dont tell you that your fucking up, those ain't your homies</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                          tweet  \\\n",
              "0                                      Beats by Dr. Dre urBeats Wired In-Ear Headphones - White https://t.co/9tREpqfyW4 https://t.co/FCaWyWRbpE   \n",
              "1                                                RT @Papapishu: Man it would fucking rule if we had a party that was against perpetual warfare.   \n",
              "2                                       It is time to draw close to Him üôèüèª Father, I draw near to you now and always ‚ù§Ô∏è https://t.co/MVRBBX2aqJ   \n",
              "3  if you notice me start to act different or distant.. it's bc i peeped something you did or i notice a difference in how you act & ian fw it.   \n",
              "4                                  Forget unfollowers, I believe in growing. 7 new followers in the last day! Stats via https://t.co/bunPHQNXhj   \n",
              "5                                          RT @Vitiligoprince: Hate Being sexually Frustrated Like I wanna Fuck But ion wanna Just fuck anybody   \n",
              "6                                      Topped the group in TGP Disc Jam Season 2! Onto the Semi-Finals! @HighHorseGames https://t.co/N7LE8lX7Rm   \n",
              "7                                   That daily baby aspirin for your #heart just might be preventing colon #cancer too. https://t.co/2TLawmHhEe   \n",
              "8                                  I liked a @YouTube video from @mattshea https://t.co/niSeJrLKHq THE BLUE ARMY IS COMING! - Ancient Warfare 2   \n",
              "9                                 RT @LestuhGang_: If your fucking up & your homies dont tell you that your fucking up, those ain't your homies   \n",
              "\n",
              "     label  \n",
              "0     spam  \n",
              "1  abusive  \n",
              "2   normal  \n",
              "3   normal  \n",
              "4   normal  \n",
              "5  abusive  \n",
              "6   normal  \n",
              "7   normal  \n",
              "8   normal  \n",
              "9  abusive  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpPCB0XDCy4H"
      },
      "source": [
        "#### 1b) Clean the tweets\n",
        "User-generated content on social media is messy, and has many artefacts that might throw off statistical analyses. Some data cleaning is almost always necessary.<br>\n",
        "Here is a function written for data cleaning. Regex replaces mentions (like \"@Paul\") with \"USR\" and URLs (starting with \"http\") with \"URL\". Newline and tab characters (\"\\n\" and \"\\t\") were removed. Excess whitespace at the beginning and end of tweets were stipped. All text was lowercased."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUaE5t68Cy4I"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "\n",
        "    # replace mentions and URLs with special token --> provide to students\n",
        "    text = re.sub(r\"@[A-Za-z0-9_-]+\",'USR',text)\n",
        "    text = re.sub(r\"http\\S+\",'URL',text)\n",
        "\n",
        "    # remove newline and tab characters\n",
        "    text = re.sub(r\"[\\n\\t]*\", \"\", text)\n",
        "\n",
        "    # strip whitespace\n",
        "    text = text.strip()\n",
        "\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1tJxqz0Cy4J"
      },
      "outputs": [],
      "source": [
        "df['tweet'] = df['tweet'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5umAj2G4Cy4K"
      },
      "source": [
        "#### 1c) Investigate duplicates\n",
        "This dataset has quite a few duplicate entries: 1) full duplicates, where tweet and label are the same, plus 2) duplicate tweets that have different labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIg6QiFrCy4K",
        "outputId": "c52cf76b-fe71-4d39-c06c-4e993173b9ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>rt usr: this fucked me up url</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>rt usr: this fucked me up url</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>rt usr: this fucked me up url</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>usr usr usr usr usr usr usr usr‚Ä¶ url</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>the abc is cutting jobs, remember?. abcnews24 is now just abc news. it's time to kiss u know what for funding for t‚Ä¶ url</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99957</th>\n",
              "      <td>found a transponder snail! scoop! exclusive photos of the mysterious mr. 0!! url #trecru url</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99960</th>\n",
              "      <td>rt usr: this fucked me up url</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99962</th>\n",
              "      <td>it's an all-too-familiar lesson for you archers: more of a goo... more for sagittarius url</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99984</th>\n",
              "      <td>rt usr: who all fucking with #littypalooza</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99986</th>\n",
              "      <td>rt usr: every fucking time url</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11420 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                          tweet  \\\n",
              "280                                                                                               rt usr: this fucked me up url   \n",
              "304                                                                                               rt usr: this fucked me up url   \n",
              "393                                                                                               rt usr: this fucked me up url   \n",
              "464                                                                                        usr usr usr usr usr usr usr usr‚Ä¶ url   \n",
              "465    the abc is cutting jobs, remember?. abcnews24 is now just abc news. it's time to kiss u know what for funding for t‚Ä¶ url   \n",
              "...                                                                                                                         ...   \n",
              "99957                              found a transponder snail! scoop! exclusive photos of the mysterious mr. 0!! url #trecru url   \n",
              "99960                                                                                             rt usr: this fucked me up url   \n",
              "99962                                it's an all-too-familiar lesson for you archers: more of a goo... more for sagittarius url   \n",
              "99984                                                                                rt usr: who all fucking with #littypalooza   \n",
              "99986                                                                                            rt usr: every fucking time url   \n",
              "\n",
              "         label  \n",
              "280    abusive  \n",
              "304    abusive  \n",
              "393    abusive  \n",
              "464     normal  \n",
              "465     normal  \n",
              "...        ...  \n",
              "99957   normal  \n",
              "99960  abusive  \n",
              "99962   normal  \n",
              "99984  abusive  \n",
              "99986  abusive  \n",
              "\n",
              "[11420 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Full duplicates\n",
        "df[df.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmxvebmICy4L",
        "outputId": "16a72dfc-269f-4146-9d36-9787c108d8f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>rt usr: this fucked me up url</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>rt usr: this fucked me up url</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>you are a force to be reckoned with wherever you go now, and ... more for aries url</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>rt usr: this fucked me up url</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>usr usr usr usr usr usr usr usr‚Ä¶ url</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99957</th>\n",
              "      <td>found a transponder snail! scoop! exclusive photos of the mysterious mr. 0!! url #trecru url</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99960</th>\n",
              "      <td>rt usr: this fucked me up url</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99962</th>\n",
              "      <td>it's an all-too-familiar lesson for you archers: more of a goo... more for sagittarius url</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99984</th>\n",
              "      <td>rt usr: who all fucking with #littypalooza</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99986</th>\n",
              "      <td>rt usr: every fucking time url</td>\n",
              "      <td>abusive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12669 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                              tweet  \\\n",
              "280                                                                   rt usr: this fucked me up url   \n",
              "304                                                                   rt usr: this fucked me up url   \n",
              "333             you are a force to be reckoned with wherever you go now, and ... more for aries url   \n",
              "393                                                                   rt usr: this fucked me up url   \n",
              "464                                                            usr usr usr usr usr usr usr usr‚Ä¶ url   \n",
              "...                                                                                             ...   \n",
              "99957  found a transponder snail! scoop! exclusive photos of the mysterious mr. 0!! url #trecru url   \n",
              "99960                                                                 rt usr: this fucked me up url   \n",
              "99962    it's an all-too-familiar lesson for you archers: more of a goo... more for sagittarius url   \n",
              "99984                                                    rt usr: who all fucking with #littypalooza   \n",
              "99986                                                                rt usr: every fucking time url   \n",
              "\n",
              "         label  \n",
              "280    abusive  \n",
              "304    abusive  \n",
              "333     normal  \n",
              "393    abusive  \n",
              "464     normal  \n",
              "...        ...  \n",
              "99957   normal  \n",
              "99960  abusive  \n",
              "99962   normal  \n",
              "99984  abusive  \n",
              "99986  abusive  \n",
              "\n",
              "[12669 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Duplicate Tweet\n",
        "df[df.duplicated(subset = 'tweet')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJMkW33NCy4M"
      },
      "source": [
        "**Q:** For each of the two types of duplicates, how would keeping them in the dataset affect our statistical analyses?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_35F1y5FCy4M"
      },
      "source": [
        "**A:** Keeping the first type would skew our model and overrepresent words in duplicated tweets in making classification decisions. Keeping the second type would 'confuse' our model since"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVNHTpbyCy4N"
      },
      "source": [
        "#### 1d) Deduplicate the data\n",
        "Drop duplicate entries, counting the number of tweets before and after dropping them. (*Hint: look into .drop_duplicates() with the \"subset\" attribute*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dNr8hLBCy4O",
        "outputId": "80c1f739-d166-4e93-c45f-298fb8e0dbb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(99996, 2)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CagErOO0Cy4Q"
      },
      "outputs": [],
      "source": [
        "df=df.drop_duplicates(subset='tweet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWAhDNcfCy4R",
        "outputId": "cac2b60f-f516-4d16-d771-51e8fa9ee186"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(87327, 2)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0r5ErIlCy4S"
      },
      "source": [
        "#### 1e) Make the tweet labels binary\n",
        "Each tweet in the dataset was originally assigned one of four labels. For this Formative, we only focus on the binary distinction between hateful and non-hateful content.<br>\n",
        "Collapse the three labels other than \"hateful\" into a single \"non-hateful\" label to make the task binary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEYp6a_ICy4S",
        "outputId": "a3fc53ee-0093-497e-886c-a04d1801f155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "normal     50596\n",
              "abusive    20149\n",
              "spam       12514\n",
              "hateful     4068\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjz0BYLfCy4S"
      },
      "outputs": [],
      "source": [
        "df['label'] = df['label'].map({'normal':'non-hateful',\n",
        "                 'abusive':'non-hateful',\n",
        "                 'spam':'non-hateful',\n",
        "                 'hateful':'hateful'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B4WkTDWCy4S"
      },
      "source": [
        "#### 1f) Describe the class distribution\n",
        "Describe the relative and absolute class distribution in the data: How many tweets and what percentage of tweets in the dataset are labelled (non-)hateful?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XR3KPK7BCy4S",
        "outputId": "b318b0ad-b736-44d2-ec3f-ccf9e3e333b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "non-hateful    83259\n",
              "hateful         4068\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L56EKn05Cy4T",
        "outputId": "1d6097c7-09c1-460f-8031-b4321b89213e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "non-hateful    0.953416\n",
              "hateful        0.046584\n",
              "Name: label, dtype: float64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3QZZCC4Cy4T"
      },
      "source": [
        "#### 1g) Tweets into lists\n",
        "\n",
        "We need to split our tweets (single strings) into lists of string tokens.\n",
        "\n",
        "The regexp selects tokens of 2 or more alphanumeric characters. Punctuation is completely ignored and always treated as a token separator. This is particularly useful for messy text like the tweets we are working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhSF9BlQCy4T"
      },
      "outputs": [],
      "source": [
        "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
        "df[\"tweet_list\"] = df.tweet.apply(lambda x: token_pattern.findall(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPaAebxOCy4T",
        "outputId": "c9b2e0b2-8d08-4475-e685-a3f90694029a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beats by dr. dre urbeats wired in-ear headphones - white url url</td>\n",
              "      <td>non-hateful</td>\n",
              "      <td>[beats, by, dr, dre, urbeats, wired, in, ear, headphones, white, url, url]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rt usr: man it would fucking rule if we had a party that was against perpetual warfare.</td>\n",
              "      <td>non-hateful</td>\n",
              "      <td>[rt, usr, man, it, would, fucking, rule, if, we, had, party, that, was, against, perpetual, warfare]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it is time to draw close to him üôèüèª father, i draw near to you now and always ‚ù§Ô∏è url</td>\n",
              "      <td>non-hateful</td>\n",
              "      <td>[it, is, time, to, draw, close, to, him, father, draw, near, to, you, now, and, always, url]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>if you notice me start to act different or distant.. it's bc i peeped something you did or i notice a difference in how you act &amp; ian fw it.</td>\n",
              "      <td>non-hateful</td>\n",
              "      <td>[if, you, notice, me, start, to, act, different, or, distant, it, bc, peeped, something, you, did, or, notice, difference, in, how, you, act, ian, fw, it]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>forget unfollowers, i believe in growing. 7 new followers in the last day! stats via url</td>\n",
              "      <td>non-hateful</td>\n",
              "      <td>[forget, unfollowers, believe, in, growing, new, followers, in, the, last, day, stats, via, url]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                          tweet  \\\n",
              "0                                                                              beats by dr. dre urbeats wired in-ear headphones - white url url   \n",
              "1                                                       rt usr: man it would fucking rule if we had a party that was against perpetual warfare.   \n",
              "2                                                           it is time to draw close to him üôèüèª father, i draw near to you now and always ‚ù§Ô∏è url   \n",
              "3  if you notice me start to act different or distant.. it's bc i peeped something you did or i notice a difference in how you act & ian fw it.   \n",
              "4                                                      forget unfollowers, i believe in growing. 7 new followers in the last day! stats via url   \n",
              "\n",
              "         label  \\\n",
              "0  non-hateful   \n",
              "1  non-hateful   \n",
              "2  non-hateful   \n",
              "3  non-hateful   \n",
              "4  non-hateful   \n",
              "\n",
              "                                                                                                                                                   tweet_list  \n",
              "0                                                                                  [beats, by, dr, dre, urbeats, wired, in, ear, headphones, white, url, url]  \n",
              "1                                                        [rt, usr, man, it, would, fucking, rule, if, we, had, party, that, was, against, perpetual, warfare]  \n",
              "2                                                                [it, is, time, to, draw, close, to, him, father, draw, near, to, you, now, and, always, url]  \n",
              "3  [if, you, notice, me, start, to, act, different, or, distant, it, bc, peeped, something, you, did, or, notice, difference, in, how, you, act, ian, fw, it]  \n",
              "4                                                            [forget, unfollowers, believe, in, growing, new, followers, in, the, last, day, stats, via, url]  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4mgc_YBCy4W"
      },
      "source": [
        "#### 1h) Split the data into a train, dev and test set\n",
        "\n",
        "Using the train_test_split function from sklearn, split df.tweet_list into a training, development and test set. Use a 70/15/15 split. Setting a fixed random_state=123, so we get the same splits as all other students."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pWMgC49Cy4W"
      },
      "outputs": [],
      "source": [
        "X = df['tweet_list'].values\n",
        "y = df['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ss7MwjYqCy4W"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "X_test, X_dev, y_test, y_dev = train_test_split(X_test, y_test, test_size=0.5, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjqwWITTCy4W"
      },
      "outputs": [],
      "source": [
        "categories = [\"hateful\", \"non-hateful\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z9VdgTCCy4X"
      },
      "outputs": [],
      "source": [
        "train_tweets, dev_tweets, test_tweets = dict(), dict(), dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsNVJSCNCy4X"
      },
      "source": [
        "#### 1i) Create vocabularies from training set\n",
        "Using our train_tweets for this.\n",
        "The Counter dictionaries should have as their keys the entries in our vocab and as their values the frequency of corresponding entries in in our train_tweets.<br>\n",
        "Then create Counter dictionaries for each category that count the number of train_tweets a given word appeared in. Those will be needed for calculating mutual information, later in the Formative.<br>\n",
        "As an example: the word \"islam\" appears 29 times in the non-hateful train_tweets, and it appears in 27 distinct non-hateful train_tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDNc1cbDCy4X"
      },
      "outputs": [],
      "source": [
        "def flatten(t):\n",
        "    return [item for sublist in t for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3JBiPouCy4Y"
      },
      "outputs": [],
      "source": [
        "for c_i in categories:\n",
        "    train_tweets[c_i] = Counter(flatten(X_train[y_train == c_i]))\n",
        "    dev_tweets[c_i] = Counter(flatten(X_dev[y_dev == c_i]))\n",
        "    test_tweets[c_i] = Counter(flatten(X_test[y_test == c_i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6jqxpVHCy4Y"
      },
      "outputs": [],
      "source": [
        "train_tweets_distinct, dev_tweets_distinct, test_tweets_distinct = dict(), dict(), dict()\n",
        "\n",
        "for c_i in categories:\n",
        "    train_tweets_distinct[c_i] = Counter(flatten([list(set(x)) for x in X_train[y_train == c_i]]))\n",
        "    dev_tweets_distinct[c_i] = Counter(flatten([list(set(x)) for x in X_dev[y_dev == c_i]]))\n",
        "    test_tweets_distinct[c_i] = Counter(flatten([list(set(x)) for x in X_test[y_test == c_i]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJx_ubvTCy4Z"
      },
      "source": [
        "**Q:** For each class, how many entries are there in the vocabulary?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OikDaSbqCy4Z",
        "outputId": "ff972c40-9464-4f31-a73f-861c32da0a0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hateful: 8001\n",
            "non-hateful: 66037\n"
          ]
        }
      ],
      "source": [
        "for c_i in categories:\n",
        "    print(f'{c_i}: {len(train_tweets[c_i])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmNsu7ibCy4h"
      },
      "source": [
        "#### 1j) Find the most frequent words in our training set\n",
        "Find the 10 most common words for each class in our training set and how often they occured."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJgfNzH6Cy4h",
        "outputId": "b36f86b5-07a9-4cca-d7e5-a0d14ad2728f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hateful: [('usr', 2349), ('the', 1291), ('url', 1282), ('to', 1004), ('you', 868), ('and', 687), ('rt', 666), ('is', 629), ('of', 577), ('that', 494)]\n",
            "non-hateful: [('url', 43496), ('usr', 41815), ('the', 24960), ('to', 20611), ('and', 14202), ('you', 14108), ('of', 11384), ('in', 10887), ('for', 9817), ('is', 9816)]\n"
          ]
        }
      ],
      "source": [
        "for c_i in categories:\n",
        "    print(f'{c_i}: {train_tweets[c_i].most_common(10)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzjO9rxmCy4i"
      },
      "source": [
        "**Q:** What type of words are these? How useful do you think they will be for the classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1kiC-eJCy4i"
      },
      "source": [
        "**A:** Many of them are stopwords and are not useful in distinguishing between hateful and non-hateful speech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "oUke8TkbCy4i"
      },
      "source": [
        "#### 1k) Load and inspect stopwords\n",
        "We use NLTK's stopword list, with added Twitter-specific stopwords such as \"rt\", \"usr\" and \"url\".<br>\n",
        "Loading the stopwords from the .txt file to a list and showing the first 10 entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJPCUxJaCy4i"
      },
      "outputs": [],
      "source": [
        "stopwords = open(\"./0_data/stopwords_formative2.txt\", \"r\").read().split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ6qCGggCy4i",
        "outputId": "427f3794-9d0f-440e-9210-a3f91306b21d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopwords[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "L41W-dXHCy4j"
      },
      "source": [
        "#### 1l) Delete stopwords from the vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fSCRIOaCy4j"
      },
      "outputs": [],
      "source": [
        "for word in stopwords:\n",
        "    if word in train_tweets['hateful']: del train_tweets['hateful'][word]\n",
        "    if word in train_tweets['non-hateful']: del train_tweets['non-hateful'][word]\n",
        "\n",
        "    if word in train_tweets_distinct['hateful']: del train_tweets_distinct['hateful'][word]\n",
        "    if word in train_tweets_distinct['non-hateful']: del train_tweets_distinct['non-hateful'][word]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcfH1sAOCy4j"
      },
      "source": [
        "To confirm that the stopwords have been deleted, coping our code from above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCcyqvX_Cy4j",
        "outputId": "cae61943-d98c-45c8-e1ab-239ce7dbcae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hateful: 7861\n",
            "non-hateful: 65891\n"
          ]
        }
      ],
      "source": [
        "for c_i in categories:\n",
        "    print(f'{c_i}: {len(train_tweets[c_i])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9aFCrvGCy4k",
        "outputId": "8a9f72c4-ed8c-497c-a424-1431ef0190e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hateful: [('hate', 429), ('fucking', 335), ('nigga', 327), ('like', 285), ('niggas', 252), ('trump', 190), ('people', 190), ('get', 176), ('idiot', 162), ('ass', 145)]\n",
            "non-hateful: [('fucking', 7197), ('like', 3541), ('get', 2837), ('one', 2240), ('new', 2009), ('fucked', 1987), ('people', 1981), ('know', 1822), ('time', 1710), ('day', 1555)]\n"
          ]
        }
      ],
      "source": [
        "for c_i in categories:\n",
        "    print(f'{c_i}: {train_tweets[c_i].most_common(10)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "OHMEUdrYCy4k"
      },
      "source": [
        "## 2) Naive Bayes, Unigrams, No Smoothing\n",
        "Training a classifier for detecting hateful tweets. We start with the simplest example from the lectures. A Naive Bayes classifier using unigrams (\"Bag-of-words Naive Bayes\"), without any smoothing. Not doing any smoothing means we can only define class-conditional probabilities $P(w|c_i)$ for features $w$ (unigrams) that appear in both classes (refered to the lectures for the maths)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZjDhCljCy4k"
      },
      "source": [
        "#### 2a) Train the classifier: get $P(w|c_i)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKlFmg8gCy4l"
      },
      "outputs": [],
      "source": [
        "# get the number of positive and negative documents\n",
        "D_pos = sum(y_train=='hateful')\n",
        "D_neg = sum(y_train=='non-hateful')\n",
        "D_tot = D_pos+D_neg\n",
        "D_pos = D_pos/D_tot\n",
        "D_neg = D_neg/D_tot\n",
        "\n",
        "# get the freq_pos\n",
        "freq_pos = train_tweets['hateful']\n",
        "\n",
        "# get the freq_neg\n",
        "freq_neg = train_tweets['non-hateful']\n",
        "\n",
        "# get total number of words\n",
        "N_pos = sum(freq_pos.values())\n",
        "N_neg = sum(freq_neg.values())\n",
        "\n",
        "# Get the V Freq\n",
        "V_freq = train_tweets['hateful']+train_tweets['non-hateful']\n",
        "\n",
        "# Get the V\n",
        "V = len(V_freq.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXxdkBreCy4l"
      },
      "outputs": [],
      "source": [
        "def calculate_proba(smoothing=False, alpha=0, trim = False, n=1000):\n",
        "    df = pd.merge(pd.DataFrame(freq_pos.items(), columns=['word','freq_pos']),\n",
        "                  pd.DataFrame(freq_neg.items(), columns=['word','freq_neg']),on='word',how='outer')\n",
        "    df = df.fillna(0)\n",
        "\n",
        "    df['prob_pos'] = df['freq_pos'].map(lambda x: (x+alpha)/(N_pos + alpha*V))\n",
        "    df['prob_neg'] = df['freq_neg'].map(lambda x: (x+alpha)/(N_neg + alpha*V))\n",
        "\n",
        "    if smoothing == False:\n",
        "        df = df[(df.freq_pos > 0) & (df.freq_neg > 0)]\n",
        "\n",
        "    if trim == True:\n",
        "        df = df[df.word.isin(most_informative[:n])]\n",
        "\n",
        "    prob_pos = dict(zip(df.word, df.prob_pos))\n",
        "    prob_neg = dict(zip(df.word, df.prob_neg))\n",
        "    return prob_pos, prob_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De_0_01wCy4l"
      },
      "outputs": [],
      "source": [
        "prob_pos, prob_neg = calculate_proba()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfQPsf87Cy4m"
      },
      "source": [
        "#### 2b) Get predictions on the test set\n",
        "\n",
        "We now have $P(w|c_i)$, but what we are ultimately interested in is $P(c_i|d)$, the probability of a given tweet $d$ being from class / category $c_i$. If $P(c_1|d)>P(c_2|d)$ we would predict $d$ to belong to $c_1$ and vice versa.\n",
        "Writing a function that you can use to get predictions on our test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Stii9IojCy4m"
      },
      "outputs": [],
      "source": [
        "def predict_text(text, prob_pos, prob_neg, smoothing=False, alpha=1): #set smoothing=True if you want the predictions to account for unseen words. We can set it to True to ignore unseen words.\n",
        "    positive = D_pos\n",
        "    negative = D_neg\n",
        "\n",
        "    for word in text:\n",
        "        if word in prob_pos:\n",
        "            positive = positive * prob_pos.get(word)\n",
        "            negative = negative * prob_neg.get(word)\n",
        "        elif smoothing == True:\n",
        "            positive = positive * alpha/(N_pos + alpha*V)\n",
        "            negative = negative * alpha/(N_pos + alpha*V)\n",
        "\n",
        "    if positive > negative:\n",
        "        return ('hateful')\n",
        "    else: return ('non-hateful')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWrCinhjCy4m"
      },
      "outputs": [],
      "source": [
        "y_pred = [predict_text(x, prob_pos, prob_neg) for x in X_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wymx0ZnRCy4n"
      },
      "source": [
        "#### 2c) Calculate test set accuracy of the classifier\n",
        "Accuracy is the percentage of labels that our classifier gave the correct label predictions for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofQcIYUmCy4n",
        "outputId": "16b3631a-b659-42b3-b9b0-5b41046e546d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  400   238]\n",
            " [ 1445 11016]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test, y_pred, labels = ['hateful', 'non-hateful']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Is_4X9VrCy4n",
        "outputId": "7bdb4855-6ae3-4303-a475-1e6c8b3c4436"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8715169096877624"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xs0jNXmCy4n"
      },
      "source": [
        "**Q:** What is it about this dataset that makes accuracy a misleading measure of performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CizDjt1rCy4n"
      },
      "source": [
        "**A:** The classes are imbalanced. Because of this, accuracy is not a very good measure of how well the model performs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYTB0o3mCy4o"
      },
      "source": [
        "#### 2d) Provide a more complete classification report\n",
        "To further investigate the performance of our classifier, printing an sklearn classification_report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rExrXKpTCy4o",
        "outputId": "b5c01b17-b369-45e7-8a68-2fc9c5d27474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     hateful       0.22      0.63      0.32       638\n",
            " non-hateful       0.98      0.88      0.93     12461\n",
            "\n",
            "    accuracy                           0.87     13099\n",
            "   macro avg       0.60      0.76      0.63     13099\n",
            "weighted avg       0.94      0.87      0.90     13099\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, labels = ['hateful', 'non-hateful']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEpMAMWQCy4o"
      },
      "source": [
        "**Q:** Briefly explain what is meant by precision and recall as well as the F1 score. Then comment on the performance of our classifier, paying particular attention to precision and recall on the hateful class as well as the macro-average F1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUTRMN9MCy4o"
      },
      "source": [
        "**A:**\n",
        "Precision: How many retrieved items are relevant? Among tweets that are classified as hateful, what is the proportion of tweets that were actually hateful?\n",
        "\n",
        "Recall: How many relevant items are retrieved? Out of all the hate speech, what is the proportion of hateful tweets that were properly classified?\n",
        "\n",
        "F1: The F1 score combines precision and recall to a single accuracy metric.\n",
        "\n",
        "The precision for hateful tweets is very low, suggesting that a lot of non-hateful tweets were classified as hateful. The recall for hateful tweets is 0.63, indicating that the model is able to flag almost 2/3s of hateful tweets. The macro average f1 score is 0.63, suggesting that the model performs better than the baseline of choosing a class at random (0.5)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrS5a4bjCy4p"
      },
      "source": [
        "#### 2e) Evaluate simple baselines\n",
        "Evaluating four simple baselines on the test set. 1) a classifier that always predicts \"hateful\", 2) a classifier that always predicts \"non-hateful\", 3) a \"uniform prior\" classifier that predicts both classes with equal probability, and 4) a \"correct prior\" classifier that predicts each class with a probability according to its prevalence in the training data. Producing classification reports for all of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il4l2FDHCy4p",
        "outputId": "d82f86e3-9462-435f-97e1-dad3b912655c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  638     0]\n",
            " [12461     0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     hateful       0.05      1.00      0.09       638\n",
            " non-hateful       0.00      0.00      0.00     12461\n",
            "\n",
            "    accuracy                           0.05     13099\n",
            "   macro avg       0.02      0.50      0.05     13099\n",
            "weighted avg       0.00      0.05      0.00     13099\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jsmed\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\jsmed\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\jsmed\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Baseline 1\n",
        "\n",
        "y_pred = ['hateful']*len(y_test)\n",
        "print(confusion_matrix(y_test, y_pred, labels = ['hateful', 'non-hateful']))\n",
        "print(classification_report(y_test, y_pred, labels = ['hateful', 'non-hateful']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLH6wMe4Cy4p",
        "outputId": "2504d99e-3641-4fae-e901-26710dee0bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[    0   638]\n",
            " [    0 12461]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jsmed\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\jsmed\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     hateful       0.00      0.00      0.00       638\n",
            " non-hateful       0.95      1.00      0.98     12461\n",
            "\n",
            "    accuracy                           0.95     13099\n",
            "   macro avg       0.48      0.50      0.49     13099\n",
            "weighted avg       0.90      0.95      0.93     13099\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jsmed\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Baseline 2\n",
        "\n",
        "y_pred = ['non-hateful']*len(y_test)\n",
        "print(confusion_matrix(y_test, y_pred, labels = ['hateful', 'non-hateful']))\n",
        "print(classification_report(y_test, y_pred, labels = ['hateful', 'non-hateful']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBU7gghnCy4q",
        "outputId": "ca1fde92-e719-4552-f8e7-776ff5013506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 338  300]\n",
            " [6227 6234]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     hateful       0.05      0.53      0.09       638\n",
            " non-hateful       0.95      0.50      0.66     12461\n",
            "\n",
            "    accuracy                           0.50     13099\n",
            "   macro avg       0.50      0.52      0.38     13099\n",
            "weighted avg       0.91      0.50      0.63     13099\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Baseline 3\n",
        "\n",
        "y_pred = random.choices(['hateful','non-hateful'], weights=[0.5,0.5], k=len(y_test))\n",
        "print(confusion_matrix(y_test, y_pred, labels = ['hateful', 'non-hateful']))\n",
        "print(classification_report(y_test, y_pred, labels = ['hateful', 'non-hateful']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSmRYz1vCy4q",
        "outputId": "d39d1039-d625-4e42-b087-5a97500281d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   29   609]\n",
            " [  579 11882]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     hateful       0.05      0.05      0.05       638\n",
            " non-hateful       0.95      0.95      0.95     12461\n",
            "\n",
            "    accuracy                           0.91     13099\n",
            "   macro avg       0.50      0.50      0.50     13099\n",
            "weighted avg       0.91      0.91      0.91     13099\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Baseline 4\n",
        "\n",
        "y_pred = random.choices(['hateful','non-hateful'], weights=np.unique(y_train, return_counts=True)[1]/len(y_train), k=len(y_test))\n",
        "print(confusion_matrix(y_test, y_pred, labels = ['hateful', 'non-hateful']))\n",
        "print(classification_report(y_test, y_pred, labels = ['hateful', 'non-hateful']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lvyliOdCy4r"
      },
      "source": [
        "**Q:** Comment on these baseline results in relation to the results of our Naive Bayes classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAmWnp2fCy4s"
      },
      "source": [
        "**A:** Baseline results generally had higher accuracy scores. However, since the classes are imbalanced, it is better to look at macro average scores. Our model outperforms the baseline models in macro average precision, recall and f1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "rHgkjq8mCy4s"
      },
      "source": [
        "## 3) Multinomial Naive Bayes, Unigrams, Additive Smoothing\n",
        "Implementing additive smoothing and evaluate different smoothing parameters. We will start using the development set to inform our parameter choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "UIFFLQ-eCy4u"
      },
      "source": [
        "#### 3a) Explain additive smoothing\n",
        "**Q:** Why would we want to use smoothing? What does it mean for the additive smoothing parameter alpha to be 1? What does it mean for alpha to be 0?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guAx_3drCy4u"
      },
      "source": [
        "**A:** If the alpha = 0, this is similar to the original formula without smoothing. If the smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5j3LaLVCy4u"
      },
      "outputs": [],
      "source": [
        "alphas = [0.0000000001]+[x * 0.05 for x in range(1, 21)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHa-u6moCy4v"
      },
      "source": [
        "Now, we want to find which alpha produces the best classifier. We will use macro F1 score as our evaluation metric, which is usually a good idea for imbalanced data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maA5BKpOCy4v",
        "outputId": "d697aba0-a1c1-4af5-d991-b8e94885d9c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 9.03 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "y_preds={}\n",
        "for alpha in alphas:\n",
        "    prob_pos_smooth, prob_neg_smooth = calculate_proba(smoothing=True, alpha=alpha)\n",
        "    y_pred = [predict_text(x, prob_pos_smooth, prob_neg_smooth, smoothing=True, alpha=alpha) for x in X_dev]\n",
        "    y_preds[alpha]=y_pred\n",
        "\n",
        "macro_f1_dict = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2uFNWDsCy4w"
      },
      "source": [
        "Find the best and worst smoothing parameter, and their corresponding macro F1 scores. Comment briefly on the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy4RxKczCy4x"
      },
      "outputs": [],
      "source": [
        "for alpha in alphas:\n",
        "    macro_f1_dict[alpha] = f1_score(y_dev, y_preds[alpha], average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8RaD589Cy4x",
        "outputId": "98075f4b-aa02-4df6-8b8c-8eb12de13d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0: 0.5212832722425329\n",
            "0.1: 0.6455224654889484\n"
          ]
        }
      ],
      "source": [
        "print(f'{min(macro_f1_dict,key=macro_f1_dict.get)}: {macro_f1_dict[min(macro_f1_dict,key=macro_f1_dict.get)]}')\n",
        "print(f'{max(macro_f1_dict,key=macro_f1_dict.get)}: {macro_f1_dict[max(macro_f1_dict,key=macro_f1_dict.get)]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P36suyCaCy4x"
      },
      "source": [
        "**A:** A lower smoothing parameter corresponds to a better macro f1 score on the development set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "nCqYDP04Cy4x"
      },
      "source": [
        "#### 3d) Visualise the results and comment\n",
        "Create a matplotlib line plot that shows the macro F1 score (y-axis) for the different values of the smoothing parameter alpha (x-axis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9tOEdE2Cy4y",
        "outputId": "dd05af4c-92ae-41fe-965a-e6867a87f42c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x2780eee0160>]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(macro_f1_dict.keys(),macro_f1_dict.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9SMf3LCCy4y"
      },
      "source": [
        "**Q:** Comment on the plot. What kind of trends are visible?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClR4FmfuCy4y"
      },
      "source": [
        "**A:** The macro f1 score peaked when alpha = 0.1. Performance deteriorated with subsequent increases in the smoothing parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "PrqqHKfLCy4y"
      },
      "source": [
        "## 4) Multinomial Naive Bayes, Unigrams, Additive Smoothing, Feature Selection\n",
        "With additive smoothing, we are using all words that appeared in either class as features in our classifier. However, intuitively, not all words will be equally useful for our task of distinguishing between hateful and non-hateful tweets. Some words may be very uninformative, or even just add noise to our classification. For example, \"lol\" appears 399 times in non-hateful tweets and 21 times a hateful tweets, and we have no clear theoretical reason for why it would be indicative of either hateful or non-hateful content.<br>\n",
        "Our final improvement to the Naive Bayes classifier will be to have it use only the most informative features. We do not want to rely on intuition to select what those are, so we use mutual information as a metric of informativeness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "i_9TxZ5yCy4y"
      },
      "source": [
        "#### 4a) Write a function to calculate mutual information\n",
        "Mutual information is only defined for features (in this case: unigrams) that appear in both classes. For those features that only appear in one class or the other, set mutual information to be 0. Refer to the lecture notes for how to calculate mutual information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTWDL-UpCy4z"
      },
      "outputs": [],
      "source": [
        "D_pos = sum(y_train=='hateful')\n",
        "D_neg = sum(y_train=='non-hateful')\n",
        "total = D_pos + D_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGWXGHCTCy4z"
      },
      "outputs": [],
      "source": [
        "def word_score(a,b,c,d):\n",
        "    word_score = (a/total) * math.log2( (total*a) / ((a+c)*(a+b)) ) + (b/total) * math.log2( (total*b) / ((b+d)*(a+b)) ) + (c/total) * math.log2( (total*c) / ((a+c)*(c+d)) ) + (d/total) * math.log2( (total*d) / ((b+d)*(c+d)) )\n",
        "    return word_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zar9_uQqCy4z"
      },
      "outputs": [],
      "source": [
        "df = pd.merge(pd.DataFrame(train_tweets_distinct['hateful'].items(), columns=['word','freq_pos']),\n",
        "              pd.DataFrame(train_tweets_distinct['non-hateful'].items(), columns=['word','freq_neg']),on='word',how='outer')\n",
        "df = df.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smIHiOUzCy4z"
      },
      "outputs": [],
      "source": [
        "df['mutual info'] = df.apply(lambda row: word_score(row.freq_pos, (D_pos-row.freq_pos),row.freq_neg, (D_neg-row.freq_neg)) if row.word in (train_tweets_distinct['hateful'].keys() & train_tweets_distinct['non-hateful'].keys()) else 0, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "6h9vCkRYCy4z"
      },
      "source": [
        "#### 4b) Find most informative features based on Mutual Information\n",
        "Store all features in a list sorted in descending order by their mutual information and print the top 30 most informative features. Comment on them. Do they match your expectations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzjirF_pCy40",
        "outputId": "62493367-0b5f-4465-a3f5-99f6255dda71"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>freq_pos</th>\n",
              "      <th>freq_neg</th>\n",
              "      <th>mutual info</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>nigga</td>\n",
              "      <td>289.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>0.014536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>hate</td>\n",
              "      <td>403.0</td>\n",
              "      <td>764.0</td>\n",
              "      <td>0.012829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>niggas</td>\n",
              "      <td>238.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>0.012362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>idiot</td>\n",
              "      <td>153.0</td>\n",
              "      <td>538.0</td>\n",
              "      <td>0.003119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>trump</td>\n",
              "      <td>174.0</td>\n",
              "      <td>1029.0</td>\n",
              "      <td>0.002077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>mad</td>\n",
              "      <td>94.0</td>\n",
              "      <td>374.0</td>\n",
              "      <td>0.001705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>hell</td>\n",
              "      <td>97.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>0.001450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>ugly</td>\n",
              "      <td>83.0</td>\n",
              "      <td>356.0</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>racist</td>\n",
              "      <td>34.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.001360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>idiots</td>\n",
              "      <td>73.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>0.001293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>stupid</td>\n",
              "      <td>89.0</td>\n",
              "      <td>494.0</td>\n",
              "      <td>0.001134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1057</th>\n",
              "      <td>muslim</td>\n",
              "      <td>30.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.000952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>894</th>\n",
              "      <td>muslims</td>\n",
              "      <td>23.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.000939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>isis</td>\n",
              "      <td>29.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.000913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545</th>\n",
              "      <td>islam</td>\n",
              "      <td>23.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.000896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>bitches</td>\n",
              "      <td>62.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>0.000895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>ass</td>\n",
              "      <td>139.0</td>\n",
              "      <td>1205.0</td>\n",
              "      <td>0.000893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>new</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1933.0</td>\n",
              "      <td>0.000879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>people</td>\n",
              "      <td>182.0</td>\n",
              "      <td>1859.0</td>\n",
              "      <td>0.000817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>nazi</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.000802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1059</th>\n",
              "      <td>females</td>\n",
              "      <td>20.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.000802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>assad</td>\n",
              "      <td>34.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>0.000762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>evil</td>\n",
              "      <td>35.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>0.000742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>syria</td>\n",
              "      <td>55.0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>0.000729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>sick</td>\n",
              "      <td>57.0</td>\n",
              "      <td>316.0</td>\n",
              "      <td>0.000723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1687</th>\n",
              "      <td>islamic</td>\n",
              "      <td>19.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.000719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>disgusting</td>\n",
              "      <td>38.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>0.000719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>like</td>\n",
              "      <td>266.0</td>\n",
              "      <td>3305.0</td>\n",
              "      <td>0.000674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>bitch</td>\n",
              "      <td>100.0</td>\n",
              "      <td>850.0</td>\n",
              "      <td>0.000662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>damn</td>\n",
              "      <td>66.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>0.000594</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            word  freq_pos  freq_neg  mutual info\n",
              "73         nigga     289.0     159.0     0.014536\n",
              "57          hate     403.0     764.0     0.012829\n",
              "84        niggas     238.0     113.0     0.012362\n",
              "95         idiot     153.0     538.0     0.003119\n",
              "26         trump     174.0    1029.0     0.002077\n",
              "256          mad      94.0     374.0     0.001705\n",
              "451         hell      97.0     469.0     0.001450\n",
              "181         ugly      83.0     356.0     0.001400\n",
              "576       racist      34.0      36.0     0.001360\n",
              "286       idiots      73.0     297.0     0.001293\n",
              "426       stupid      89.0     494.0     0.001134\n",
              "1057      muslim      30.0      53.0     0.000952\n",
              "894      muslims      23.0      23.0     0.000939\n",
              "153         isis      29.0      52.0     0.000913\n",
              "545        islam      23.0      26.0     0.000896\n",
              "354      bitches      62.0     308.0     0.000895\n",
              "117          ass     139.0    1205.0     0.000893\n",
              "18           new      24.0    1933.0     0.000879\n",
              "164       people     182.0    1859.0     0.000817\n",
              "1127        nazi      18.0      14.0     0.000802\n",
              "1059     females      20.0      21.0     0.000802\n",
              "411        assad      34.0     104.0     0.000762\n",
              "329         evil      35.0     115.0     0.000742\n",
              "99         syria      55.0     294.0     0.000729\n",
              "235         sick      57.0     316.0     0.000723\n",
              "1687     islamic      19.0      23.0     0.000719\n",
              "321   disgusting      38.0     143.0     0.000719\n",
              "127         like     266.0    3305.0     0.000674\n",
              "112        bitch     100.0     850.0     0.000662\n",
              "212         damn      66.0     469.0     0.000594"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.sort_values('mutual info', ascending=False)\n",
        "df.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57B3PksPCy40"
      },
      "outputs": [],
      "source": [
        "most_informative = df.word.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "bEhK79gsCy40"
      },
      "source": [
        "**A:** Informative features include words with connotations that can be hateful depending on context (e.g. n word, bitch) and words referring to populations that are often the targets of hate speech (females, muslim)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "CSONn-WFCy44"
      },
      "source": [
        "#### 4a) Find the optimal number of features\n",
        "We now want to tune the number of most-informative features as a hyperparameter. Use the optimal smoothing parameter you found before. If you did not complete the earlier question, use smoothing_alpha = 0.1. (Note that it is not guaranteed that the best smoothing parameter you found earlier is still optimal for any choice of top_n. We stick with the best smoothing parameter we found earlier to simplify things.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nRk2-zpCy45"
      },
      "outputs": [],
      "source": [
        "top_ns = [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzAzARpJCy45",
        "outputId": "c5df8ff6-1ebb-44d3-daf9-0c31cf130d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 6.68 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "y_preds={}\n",
        "for n in top_ns:\n",
        "    prob_pos_smooth, prob_neg_smooth = calculate_proba(smoothing=True, alpha=0.1, trim = True, n=n)\n",
        "    y_pred = [predict_text(x, prob_pos_smooth, prob_neg_smooth, smoothing=True, alpha=alpha) for x in X_dev]\n",
        "    y_preds[n]=y_pred\n",
        "\n",
        "macro_f1_dict = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvszWHLNCy46"
      },
      "source": [
        "Find the best and worst values for N, and their corresponding macro F1 scores. Comment briefly on the results, comparing them to your results from when you were using additive smoothing without feature selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JClmADetCy47"
      },
      "outputs": [],
      "source": [
        "for n in top_ns:\n",
        "    macro_f1_dict[n] = f1_score(y_dev, y_preds[n], average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BJrpB5ICy47",
        "outputId": "e6771d36-c818-4b16-99f5-529762342fa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: 0.5573942194709003\n",
            "200: 0.6643124352454544\n"
          ]
        }
      ],
      "source": [
        "print(f'{min(macro_f1_dict,key=macro_f1_dict.get)}: {macro_f1_dict[min(macro_f1_dict,key=macro_f1_dict.get)]}')\n",
        "print(f'{max(macro_f1_dict,key=macro_f1_dict.get)}: {macro_f1_dict[max(macro_f1_dict,key=macro_f1_dict.get)]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojf8l87JCy47"
      },
      "source": [
        "**A:** The naive bayes model with smoothing (alpha = 0.1) and feature selection (n = 200) outperformed the model with smoothing (0.64), getting a macro f1 of 0.66 on the dev set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "LKV6HV85Cy47"
      },
      "source": [
        "#### 4b) Visualise the results and comment\n",
        "Create a matplotlib line plot that shows the macro F1 score (y-axis) for the different numbers of most-informative features (x-axis). You may want to use a log-scale for the x-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0GL6Sm9Cy48",
        "outputId": "f1e0039b-81f8-4824-e5bb-f0d4ba4819ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x2781002f700>]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(macro_f1_dict.keys(),macro_f1_dict.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrC80wtgCy48"
      },
      "source": [
        "**Q:** Comment on the plot. What kind of trends are visible?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb5LlIJLCy48"
      },
      "source": [
        "**A:** The f1 score spiked when n = 200. Afterward, the f1 score went down and stabilized around 0.64. We can observe very marginal increase in macro f1 as we increase the number of features. However, it doesn't reach our max f1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "ZEaZ_FjACy48"
      },
      "source": [
        "## 5) Error Analysis\n",
        "We have built a Naive Bayes classifier from scratch using pure Python, and we improved it by adding additive smoothing and feature selection based on mutual information. The end result is a classifier that still does not perform great, but it is a useful baseline that we understand well.<br>\n",
        "At this final stage, it is good practice to manually inspect some of the errors made by our classifier, to create hypotheses about its weaknesses, so we can address them in future work. You will see this kind of analysis in many research articles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_rIUOAYCy49"
      },
      "source": [
        "#### 5a) Train and evaluate our best classifier so far\n",
        "Using your findings from above, train the classifier that performed best on the dev set. Get its predictions on the test set and print a classification report. If you could not make additive smoothing and/or feature selection work, use the simplest implementation of Naive Bayes that did work for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvn8-TBPCy49",
        "outputId": "38919c1c-f70f-4d04-c998-0817ca130670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  232   406]\n",
            " [  329 12132]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     hateful       0.41      0.36      0.39       638\n",
            " non-hateful       0.97      0.97      0.97     12461\n",
            "\n",
            "    accuracy                           0.94     13099\n",
            "   macro avg       0.69      0.67      0.68     13099\n",
            "weighted avg       0.94      0.94      0.94     13099\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prob_pos_smooth, prob_neg_smooth = calculate_proba(smoothing=True, alpha=0.1, trim = True, n=200)\n",
        "y_pred = [predict_text(x, prob_pos_smooth, prob_neg_smooth, smoothing=True, alpha=alpha) for x in X_test]\n",
        "print(confusion_matrix(y_test, y_pred, labels = ['hateful', 'non-hateful']))\n",
        "print(classification_report(y_test, y_pred, labels = ['hateful', 'non-hateful']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "kKo7Y3ZvCy49"
      },
      "source": [
        "#### 5b) Inspect false positives\n",
        "We are interested in detecting hateful tweets, so \"hateful\" is our positive class and \"non-hateful\" our negative class.<br>\n",
        "Print and inspect a sample of 10 tweets that were falsely predicted to be \"hateful\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiM9pY99Cy49",
        "outputId": "8e1288c9-e291-4cc8-da6c-f478c443007c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([list(['usr', 'as', 'said', 'mans', 'levels', 'nd', 'haters', 'gon', 'hate', 'same', 'thing', 'think', 'bout', 'you', 'so', 'you', 'can', 'keep', 'on', 'chatting', 'bar', 'url']),\n",
              "       list(['usr', 'but', 'usr', 'are', 'better', 'than', 'the', 'republicans', 'because', 'uh', 'some', 'of', 'us', 'like', 'the', 'gays', 'only', 'bill', 'url']),\n",
              "       list(['rt', 'usr', 'why', 'hate', 'louisiana', 'niggas', 'url']),\n",
              "       list(['rt', 'usr', 'always', 'ugly', 'to', 'bitch', 'that', 'don', 'like', 'me', 'always', 'scary', 'to', 'bitch', 'that', 'won', 'fight', 'me', 'just', 'that', 'bitch']),\n",
              "       list(['mikepence', 'not', 'being', 'able', 'to', 'have', 'dinner', 'alone', 'with', 'any', 'woman', 'other', 'than', 'his', 'wife', 'etc', 'is', 'just', 'like', 'being', 'strict', 'muslim', 'ironic']),\n",
              "       list(['usr', 'my', 'worst', 'experience', 'with', 'red', 'light', 'triggers', 'one', 'idiot', 'stopped', 'in', 'front', 'of', 'it', 'other', 'idiot', 'stopped', 'be', 'url']),\n",
              "       list(['rt', 'usr', 'hate', 'seeing', 'my', 'friends', 'sad', 'shit', 'they', 'don', 'deserve', 'to', 'be', 'going', 'through', 'this', 'they', 'deserve', 'the', 'damn', 'world']),\n",
              "       list(['rt', 'usr', 'me', 'watching', 'liberal', 'platforms', 'being', 'hijacked', 'by', 'unreasonable', 'idiots', 'url']),\n",
              "       list(['rt', 'usr', 'why', 'does', 'trump', 'still', 'endbup', 'on', 'my', 'twitter', 'dint', 'follow', 'you', 'ugly', 'ass', 'bitch', 'get', 'out', 'of', 'here']),\n",
              "       list(['usr', 'usr', 'if', 'it', 'wasn', 'for', 'the', 'muslims', 'sihks', 'and', 'hindus', 'in', 'the', 'trenches', 'and', 'flying', 'the', 'spitfires', 'we', 'be', 'fucked'])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask=[]\n",
        "for x,y in zip([y == 'non-hateful' for y in y_test], [y == 'hateful' for y in y_pred]):\n",
        "    mask.append((x==y==True))\n",
        "X_test[mask][0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxVgCCLeCy4-"
      },
      "source": [
        "**Q:** Comment on these errors. Can you spot any patterns and think of potential explanations for why these tweets were falsely predicted to be \"hateful\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2O4gu5UCy4-"
      },
      "source": [
        "The model cannot predict the slang usage of words like bitch. It is also possible that words refering to sensitive populations that are often targeted by hate speech (e.g. muslims) often appear in hate speech in the dataset, hence, the model is not able to nuance between differing uses of the word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Ms3v3onXCy4-"
      },
      "source": [
        "#### 5c) Inspect false negatives\n",
        "Print and inspect a sample of 15 tweets that were falsely predicted to be \"non-hateful\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjBt1_r7Cy4-",
        "outputId": "836b6efa-2ab1-4490-ed67-a449e00a766c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([list(['usr', 'usr', 'thought', 'gop', 'trump', 'want', 'everything', 'decided', 'locally', 'or', 'by', 'the', 'states', 'dangerous', 'hypocrites']),\n",
              "       list(['hillary', 'scott', 'is', 'filthy', 'fuckin', 'fuck', 'pig', 'url']),\n",
              "       list(['psychiatrists', 'appear', 'addicted', 'to', 'the', 'pain', 'suffering', 'they', 'cause', 'people', 'url']),\n",
              "       list(['happy', '18th', 'to', 'the', 'meanest', 'sassiest', 'and', 'rudest', 'person', 'know', 'so', 'glad', 'we', 'became', 'friends', 'after', 'you', 'slapped', 'me', 'in', 'the', 'url']),\n",
              "       list(['usr', 'that', 'reminds', 'me', 'need', 'to', 'pick', 'up', 'one', 'of', 'those', 'fake', 'headrest', 'switch', 'mounts', 'before', 'deluxe', 'hits', 'so', 'that', 'url']),\n",
              "       list(['usr', 'usr', 'stupid', 'fucking', 'leftists', 'can', 'understand', 'why', 'labor', 'organizer', 'is', 'opposed', 'to', 'illegal', 'im', 'url']),\n",
              "       list(['usr', 'usr', 'usr', 'usr', 'usr', 'is', 'this', 'what', 'happens', 'when', 'you', 'niggas', 'run', 'out', 'out', 'power', 'fucked', 'up']),\n",
              "       list(['springer', 'can', 'steal', 'base', 'but', 'that', 'fucker', 'can', 'hit', 'the', 'ball', 'hell', 'of', 'game', 'astros', 'springerdinger']),\n",
              "       list(['bryce', 'from', '13', 'reasons', 'why', 'is', 'one', 'of', 'the', 'most', 'disgusting', 'and', 'repulsive', 'characters', 'from', 'anything', 've', 'ever', 'read', 'watched']),\n",
              "       list(['usr', 'this', 'is', 'crminal', 'corruption', 'clinton', 'aides', 'had', 'access', 'to', 'state', 'dept', 'after', 'she', 'left', 'says', 'key', 'lawmaker', 'this', 'is', 'treasonous']),\n",
              "       list(['question', 'did', 'soros', 'fund', 'syrian', 'gas', 'attack', 'usr', 'usr', 'usr', 'usr', 'url']),\n",
              "       list(['usr', 'usr', 'someone', 'remind', 'me', 'again', 'what', 'this', 'idiot', 'woman', 'is', 'employed', 'as']),\n",
              "       list(['usr', 'usr', 'you', 're', 'idiot', 'blind', 'not', 'me']),\n",
              "       list(['too', 'bad', 'size', '11', 'men', 'and', 'got', 'basketball', 'torn', 'up', 'ass', 'feet', 'url']),\n",
              "       list(['usr', 'usr', 'usr', 'learn', 'to', 'spell', 'before', 'you', 'comment', 'ivanka', 'is', 'major', 'nusinesz', 'woman', 'with', 'world', 'url'])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask=[]\n",
        "for x,y in zip([y == 'hateful' for y in y_test], [y == 'non-hateful' for y in y_pred]):\n",
        "    mask.append((x==y==True))\n",
        "X_test[mask][0:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYygz_PXCy4_"
      },
      "source": [
        "**Q:** Comment on these errors. Can you spot any patterns and think of potential explanations for why these tweets were falsely predicted to be \"non-hateful\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyhaU856Cy5A"
      },
      "source": [
        "**A:** The words were possibly falsely predicted as non-hateful because they contain a lot of words that aren't necessarily offensive but can be used in an offensive manner."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}